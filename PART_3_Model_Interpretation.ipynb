{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PART-3_Model_Interpretation.ipynb",
      "provenance": [],
      "mount_file_id": "1R4deS-GpEKAiT6_WR5bk_9UIx9Z0adcS",
      "authorship_tag": "ABX9TyPQayOG1cZMYvRZwdjRXfMG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MashaKubyshina/Learning_to_code/blob/master/PART_3_Model_Interpretation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cKROyYMtUmL"
      },
      "source": [
        "# The code is from this tutorial https://towardsdatascience.com/text-classification-in-python-dd95d264c802"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rRi3QPG3T-W"
      },
      "source": [
        "# In this project I selected Random Forest model to do preditions"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCKie-pytexY"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import punkt\n",
        "from nltk.corpus.reader import wordnet\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJvazhl2uAw9"
      },
      "source": [
        "# we will load all Pickle files\n",
        "\n",
        "# Dataframe\n",
        "path_df = \"/content/drive/MyDrive/Pickles/df.pickle\"\n",
        "with open(path_df, 'rb') as data:\n",
        "    df = pickle.load(data)\n",
        "    \n",
        "# X_train\n",
        "path_X_train = \"/content/drive/MyDrive/Pickles/X_train.pickle\"\n",
        "with open(path_X_train, 'rb') as data:\n",
        "    X_train = pickle.load(data)\n",
        "\n",
        "# X_test\n",
        "path_X_test = \"/content/drive/MyDrive/Pickles/X_test.pickle\"\n",
        "with open(path_X_test, 'rb') as data:\n",
        "    X_test = pickle.load(data)\n",
        "\n",
        "# y_train\n",
        "path_y_train = \"/content/drive/MyDrive/Pickles/y_train.pickle\"\n",
        "with open(path_y_train, 'rb') as data:\n",
        "    y_train = pickle.load(data)\n",
        "\n",
        "# y_test\n",
        "path_y_test = \"/content/drive/MyDrive/Pickles/y_test.pickle\"\n",
        "with open(path_y_test, 'rb') as data:\n",
        "    y_test = pickle.load(data)\n",
        "\n",
        "# features_train\n",
        "path_features_train = \"/content/drive/MyDrive/Pickles/features_train.pickle\"\n",
        "with open(path_features_train, 'rb') as data:\n",
        "    features_train = pickle.load(data)\n",
        "\n",
        "# labels_train\n",
        "path_labels_train = \"/content/drive/MyDrive/Pickles/labels_train.pickle\"\n",
        "with open(path_labels_train, 'rb') as data:\n",
        "    labels_train = pickle.load(data)\n",
        "\n",
        "# features_test\n",
        "path_features_test = \"/content/drive/MyDrive/Pickles/features_test.pickle\"\n",
        "with open(path_features_test, 'rb') as data:\n",
        "    features_test = pickle.load(data)\n",
        "\n",
        "# labels_test\n",
        "path_labels_test = \"/content/drive/MyDrive/Pickles/labels_test.pickle\"\n",
        "with open(path_labels_test, 'rb') as data:\n",
        "    labels_test = pickle.load(data)\n",
        "    \n",
        "# Random Forest Model\n",
        "path_model = \"/content/drive/MyDrive/Pickles/Models/best_rfc.pickle\"\n",
        "with open(path_model, 'rb') as data:\n",
        "    rfc_model = pickle.load(data)\n",
        "    \n",
        "# Category mapping dictionary\n",
        "category_codes = {\n",
        "    'Computer/Tech': 0,\n",
        "    'Engineering/Architecture': 1,\n",
        "    'Business/Consulting': 2\n",
        "}\n",
        "\n",
        "category_names = {\n",
        "    0: 'Computer/Tech',\n",
        "    1: 'Engineering/Architecture',\n",
        "    2: 'Business/Consulting'\n",
        "}"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6djODdOvvA8-"
      },
      "source": [
        "# predictions on test set\n",
        "\n",
        "predictions = rfc_model.predict(features_test)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcHVbDyivKRR"
      },
      "source": [
        "# Test set dataframe with actual and predicted categories\n",
        "\n",
        "# Indexes of the test set\n",
        "index_X_test = X_test.index\n",
        "\n",
        "# We get them from the original df\n",
        "df_test = df.loc[index_X_test]\n",
        "\n",
        "# Add the predictions\n",
        "df_test['Prediction'] = predictions\n",
        "\n",
        "# Clean columns\n",
        "df_test = df_test[['job_description', 'category', 'Category_Code', 'Prediction']]\n",
        "\n",
        "# Decode\n",
        "df_test['Category_Predicted'] = df_test['Prediction']\n",
        "df_test = df_test.replace({'Category_Predicted': category_names})\n",
        "\n",
        "# Clean columns again\n",
        "df_test = df_test[['job_description', 'category', 'Category_Predicted']]"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "1sRJzvBrw7zv",
        "outputId": "ff39ee6a-87b8-4f88-a431-d1bad35f85ac"
      },
      "source": [
        "# Let's check actual category and category predicted by RFC model\n",
        "\n",
        "df_test.head()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_description</th>\n",
              "      <th>category</th>\n",
              "      <th>Category_Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4005</th>\n",
              "      <td>Job Description\\n\\nPerforms data analysis, int...</td>\n",
              "      <td>Computer/Tech</td>\n",
              "      <td>Computer/Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2457</th>\n",
              "      <td>TTEC requires all employees hired in the Unite...</td>\n",
              "      <td>Engineering/Architecture</td>\n",
              "      <td>Engineering/Architecture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>At Actian we believe data should be used as a ...</td>\n",
              "      <td>Business/Consulting</td>\n",
              "      <td>Business/Consulting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1728</th>\n",
              "      <td>Senior Data Scientist Duties Work with Retail,...</td>\n",
              "      <td>Business/Consulting</td>\n",
              "      <td>Business/Consulting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3909</th>\n",
              "      <td>Job Description\\n\\nWe are looking for a highly...</td>\n",
              "      <td>Computer/Tech</td>\n",
              "      <td>Engineering/Architecture</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        job_description  ...        Category_Predicted\n",
              "4005  Job Description\\n\\nPerforms data analysis, int...  ...             Computer/Tech\n",
              "2457  TTEC requires all employees hired in the Unite...  ...  Engineering/Architecture\n",
              "357   At Actian we believe data should be used as a ...  ...       Business/Consulting\n",
              "1728  Senior Data Scientist Duties Work with Retail,...  ...       Business/Consulting\n",
              "3909  Job Description\\n\\nWe are looking for a highly...  ...  Engineering/Architecture\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "tVrIrYPSxHf2",
        "outputId": "5c505751-cbde-46b2-8dc7-8ff01332687e"
      },
      "source": [
        "# Let's get missclassifed job_descriptions\n",
        "\n",
        "condition = (df_test['category'] != df_test['Category_Predicted'])\n",
        "\n",
        "df_misclassified = df_test[condition]\n",
        "\n",
        "df_misclassified.head(3)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_description</th>\n",
              "      <th>category</th>\n",
              "      <th>Category_Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3909</th>\n",
              "      <td>Job Description\\n\\nWe are looking for a highly...</td>\n",
              "      <td>Computer/Tech</td>\n",
              "      <td>Engineering/Architecture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>AWS Data Scientist- Computer Software- Minneso...</td>\n",
              "      <td>Engineering/Architecture</td>\n",
              "      <td>Business/Consulting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2714</th>\n",
              "      <td>Credit Sesame is the nation’s only full-lifecy...</td>\n",
              "      <td>Engineering/Architecture</td>\n",
              "      <td>Computer/Tech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        job_description  ...        Category_Predicted\n",
              "3909  Job Description\\n\\nWe are looking for a highly...  ...  Engineering/Architecture\n",
              "888   AWS Data Scientist- Computer Software- Minneso...  ...       Business/Consulting\n",
              "2714  Credit Sesame is the nation’s only full-lifecy...  ...             Computer/Tech\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqFRYGMaxT5U"
      },
      "source": [
        "# Function to get the sample of 3 missclasifed job postings\n",
        "\n",
        "def output_article(row_article):\n",
        "    print('Actual Category: %s' %(row_article['category']))\n",
        "    print('Predicted Category: %s' %(row_article['Category_Predicted']))\n",
        "    print('-------------------------------------------')\n",
        "    print('Text: ')\n",
        "    print('%s' %(row_article['job_description']))"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmE9ope6xeBw",
        "outputId": "c8486298-d2d9-4e57-bd5a-f01dc4386518"
      },
      "source": [
        "# get random number of indices\n",
        "\n",
        "random.seed(8)\n",
        "list_samples = random.sample(list(df_misclassified.index), 5)\n",
        "list_samples"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2524, 781, 949, 714, 1778]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN3IQp0yxkqt",
        "outputId": "840b2106-043e-44c9-9cd2-3d533fcde818"
      },
      "source": [
        "# Let's look at all 3 job postings\n",
        "\n",
        "# first one\n",
        "\n",
        "\n",
        "output_article(df_misclassified.loc[list_samples[0]])"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual Category: Business/Consulting\n",
            "Predicted Category: Computer/Tech\n",
            "-------------------------------------------\n",
            "Text: \n",
            "Look for more than answers.   At Quest, we are on a continuous journey of discovery and development. It’s this attitude that has made us an industry leader and the #1 Diagnostic Lab in the US. For those joining us, we offer exciting and fast-moving career opportunities where you can affect change at a rate unheard of in many organizations of our size and scope. While we invest in and develop technology to drive our innovations, our ongoing success relies on our people. As a Data Scientist, you will work for the world leader in the industry, with a career where you will have the opportunity to collaborate and affect change while expanding your leadership skills and technical knowledge. You can make a real impact in a market that is growing and developing. Data Scientist, the role:   The Data Scientist will support the franchises by using internal Quest Diagnostics data and externally purchased market data to inform key business decisions.  The main purpose of this role is to turn data into insights that drive key decisions for the organization and our clients. Job responsibilities: Provide biostatistical consultation to clients or colleagues. Analyze archival data such as laboratory, medical, prescription, and death records. Read current literature, attend meetings or conferences, and talk with colleagues to keep abreast of methodological or conceptual developments in fields such as actuarial sciences, data science, biostatistics, risk management, pharmacology, life sciences, and social sciences. Prepare articles for publication or presentation at professional conferences. Calculate sample size requirements for studies. Write program code to analyze data and develop predictive models using SAS statistical analysis software. Write detailed analysis plans and descriptions of analyses and findings for research protocols or reports. Prepare tables and graphs to present data or results. Draw conclusions or make predictions based on data summaries or statistical analyses. Develop or implement data analysis and reporting algorithms. Design research studies in collaboration with physicians, life scientists, underwriters, or other professionals. Analyze data using statistical approaches such as longitudinal analysis, mixed effect modeling, logistic regression analyses proportional hazards regression, and other model building techniques. To qualify, the ideal candidate will have the following: Bachelor’s degree in Actuarial Sciences, Biostatistics, Mathematics, Risk Management, Data Science or other closely related field.  Experience and demonstrable success will be considered in place of education Master’s degree in Actuarial Sciences, Biostatistics, or Data Science preferred Experience working with datasets in the life insurance and/or health care industries.  Experience with SAS strongly preferred.  Experience with other statistical languages such as R and Python will be considered. Knowledge of arithmetic, algebra, geometry, calculus, statistics, and their applications. Ability to use advanced statistics and mathematics to solve problems and develop models.  Additional skills preferred: Statistics/Mathematics -- Using advanced statistics and mathematics to solve problems and develop models.  Critical Thinking -- Using logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions or approaches to problems. Complex Problem Solving -- Identifying complex problems and reviewing related information to develop and evaluate options and implement solutions. Judgment and Decision Making -- Considering the relative costs and benefits of potential actions to choose the most appropriate one. Science -- Using scientific rules and methods to solve problems. Writing -- Communicating effectively in writing as appropriate for the needs of the audience. Reading Comprehension -- Understanding written sentences and paragraphs in work related documents. Active Listening -- Giving full attention to what other people are saying, taking time to understand the points being made, asking questions as appropriate, and not interrupting at inappropriate times. Active Learning -- Understanding the implications of new information for both current and future problem-solving and decision-making. Speaking -- Talking to others to convey information effectively, including in the context of formal industry presentations.. Programming -- Writing SAS statistical and other computer programs for various purposes. Learning Strategies -- Selecting and using largely self-directed training/instructional methods and procedures appropriate for the situation when learning or teaching new things. Apply Today Join us for competitive benefits and development opportunities in a progressive and supportive environment. Help us improve our service, and the experiences of our patients and colleagues. Work with us and together we can be better.   Your Quest career. Seek it out. All requirements are subject to possible modifications to reasonably accommodate individuals with disabilities. Quest Diagnostics is an Equal Opportunity Employer: Women / Minorities / Veterans / Disabled / Sexual Orientation / Gender Identity. *cb*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1On98Ckx5FS",
        "outputId": "74a77f4b-5509-4f7b-f9f0-c7b234906492"
      },
      "source": [
        "# second missclasifed job description\n",
        "\n",
        "output_article(df_misclassified.loc[list_samples[1]])"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual Category: Business/Consulting\n",
            "Predicted Category: Computer/Tech\n",
            "-------------------------------------------\n",
            "Text: \n",
            "Job Title: Data Analyst/Data Scientist Location: San Francisco, CA Duration: 3+ months   CTH Responsibilities: • Skilled at defining and asking key questions that help clients discover their needs, building trust by communicating effectively with clients about status and issues, developing and presenting convincing recommendations that address key client objectives, setting appropriate expectations with client and managing them throughout the project life cycle • Analyze industry trends, conducting discussions for insights, interpreting dataextensive healthcare repository, examining models and tools, formulating studies and making recommendations to stakeholders. Design, build and deploy BI solutions in Tableau and create ad-hoc reports as needed • Support all aspects of projects; including formulating research and analysis plans, developing strategies instrumental in product success, managing data collection, executing data analysis, writing reports, and presenting findings while ensuring quality and accuracy. Provide on-going tracking and monitoring of performance decision systems and statistical models • Owning projects end-to-end and working in a multidisciplinary team that is agile in their approach to analytics, ensuring that everything they do is applied to the wider business. • Develop effective, defect free analysis and visual insights that meet business requirements and explain findings efficiently Skill Set Desired: Desired Skills • Ability to tackle problems by using a logical, systematic, and sequential approach • Prior experience and/or demonstrated desire to understand business workflows and promote data driven decision making within business teams • Recognizes abstract patterns and relationships between apparently unrelated entities or situations using statistical techniques • Experience with Analytics tools such as Tableau; Databases including SQL Server, Netezza etc. • Translate business requirements into data requirements with a deep understanding of project objectives and available data attributes • Excellent analytical, problem solving, and communication and collaboration skills • Must be proactive, demonstrate initiative, and be a logical thinker • Strong oral, written communication, and presentation skills. Ability to present complex information in an understandable and compelling manner • Proven experience working in a business intelligence analytics environment, delivering insights and recommendations across the organizations Qualifications • Bachelor’s degree in a relevant field of study (health sciences, computer science, engineering or other quantitative discipline • High proficiency with SQL, Tableau, and Excel Highly Competitive Candidates Will Have • Experience with Python/R • Prior work experience in the Healthcare industry domain • Experience in writing predictive algorithms and building sound statistical models • Foundational knowledge or proficient in new and emerging technologies such as Azure, Spark, Hadoop etc. is a plus Remote candidates are accepted as long as willing to be in office 4 days per month. (Examples: every Wednesday or one entire week per month) | \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRSY9nrdyFx9",
        "outputId": "461c493a-f159-4f8e-e186-ac7b738b3a15"
      },
      "source": [
        "# third case\n",
        "\n",
        "output_article(df_misclassified.loc[list_samples[2]])"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual Category: Engineering/Architecture\n",
            "Predicted Category: Computer/Tech\n",
            "-------------------------------------------\n",
            "Text: \n",
            "Read what people are saying about working here. \n",
            "\n",
            "Part-time, Internship\n",
            "\n",
            "ENGIE Insight, formerly Ecova, partners with multi-site businesses that aim to thrive in a sustainable world. With a foundation of accurate and comprehensive resource data – including energy, water, waste and telecom – we apply technology and people expertise to lower costs, drive efficiencies and reduce environmental impact. More than 1,000 customers, including 25%+ of the Fortune 500, turn to ENGIE Insight to help move their sustainable resource management initiatives forward.\n",
            "\n",
            "ENGIE Insight’s people are our greatest strength, bound by our vision to enable a sustainable world where people, organizations and the environment thrive. We are passionate about making our company and the world a better place; responsible in working with commitment and accountability; collaborative with our colleagues and clients, and agile enough to work in a dynamic, changing industry.\n",
            "\n",
            "The wide-ranging expertise of our diverse team fuels the innovation that places us on the leading edge of the energy industry. As such, we nurture a company culture—through training, mentoring and professional development—that encourages all employees to thrive. If this the kind of place you see yourself working, we invite you to join ENGIE Insight.\n",
            "\n",
            "*In order to be considered for the role, your resume must be attached in your application.\n",
            "\n",
            "Position Summary\n",
            "\n",
            "The Associate Data Scientist-Internship will be joining an industry-leading R&D team with extensive academic and industry experience in building energy analytics, solving physical system-based real-life big data problems. The Associate Data Scientist’s work will support the development of new algorithms used to help solve the real-world energy problems.\n",
            "\n",
            "Role Description\n",
            "\n",
            "Mine industrial-size data sets in various states of cleanliness for insights\n",
            "\n",
            "Refine and verify statistical and machine learning algorithms within the Analytics R&D group\n",
            "\n",
            "Assist the Analytics R&D team in running energy and algorithmic models and interpreting the results\n",
            "\n",
            "Evaluate business and technology trade-offs and report them in a manner that product and business teams can make decisions on final specifications\n",
            "\n",
            "Qualifications\n",
            "\n",
            "Role Competencies\n",
            "\n",
            "BS required, advanced degree in Computer Science, Engineering, Statistics, or equivalent field desired\n",
            "\n",
            "Strong mathematical background with teachable knowledge of various analytic methodologies such as signal processing, model selection, model verification, optimization, artificial neural networks, Bayesian, etc.\n",
            "\n",
            "0-3 years of experience developing, testing, and evaluating algorithms including statistical and machine learning\n",
            "\n",
            "Proficient in large-scale SQL/NoSQL database queries, with associated statistical analyses including the following areas: non-linear and multi-variate regressions, logistic regression, time series analyses, and probabilistic and classification models.\n",
            "\n",
            "Intermediate level knowledge of statistical tools (e.g., R, MatLab, etc.)\n",
            "\n",
            "Familiarity with scripting prototyping/scripting languages, e.g., Python\n",
            "\n",
            "Experience with real-world commercial data analytics and visualization\n",
            "\n",
            "Comfortable with working in a fast-paced multidisciplinary environment while maintaining strict customer data privacy requirements\n",
            "\n",
            "Uncompromising integrity and ethical standards\n",
            "\n",
            "Familiarity with cloud storage and processing technologies is desired\n",
            "\n",
            "ENGIE Insight Information\n",
            "\n",
            "Our salaries are competitive and commensurate with experience. We are a performance-based culture and have goal-based incentive programs and generous employee benefits. Our comprehensive benefit package includes medical, dental, vision insurance, life, AD&D, short- and long-term disability insurance. We also offer flexible spending accounts and 401(k) with a generous employer match.\n",
            "\n",
            "ENGIE Insight is an equal opportunity and affirmative action employer. All qualified applicants will be considered without regard to age, race, color, national origin, ancestry, sex, sexual orientation or preference, religion, marital status, citizenship, veteran status, or physical or mental disability.\n",
            "\n",
            "Connect with ENGIE Insight: Twitter | LinkedIn | Facebook | Blog | Videos | Webinars\n",
            "\n",
            "Job\n",
            "\n",
            ": Digital and IT\n",
            "\n",
            "Primary Location\n",
            "\n",
            ": North America-United States-Massachusetts-Boston\n",
            "\n",
            "Organization\n",
            "\n",
            ": Technology\n",
            "\n",
            "Schedule\n",
            "\n",
            ": Part-time\n",
            "\n",
            "Nature of Responsibility\n",
            "\n",
            ": Advanced operational / administrative role\n",
            "\n",
            "Job Posting\n",
            "\n",
            ": Mar 5, 2019, 8:42:28 PM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyvSJu3eyWYq",
        "outputId": "8356c5ff-9855-48d6-f9e9-a9f6ff859cea"
      },
      "source": [
        "# Fourth case\n",
        "\n",
        "output_article(df_misclassified.loc[list_samples[3]])"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual Category: Engineering/Architecture\n",
            "Predicted Category: Computer/Tech\n",
            "-------------------------------------------\n",
            "Text: \n",
            "Read what people are saying about working here. \n",
            "\n",
            "The Applied Analytics COE team isresponsible for developing analytics-driven solutions to help GM Organizations achievetheir business goals. The individual will work as a member of amulti-disciplinary team of various experience levels that will be drivingsolution design, development, and deployment of analytic models in support ofbusiness facing analytic groups. The team is responsible for bothadvanced analytics strategy and applied, project-based solutions, focusing onthe company’s most critical business areas.\n",
            "\n",
            "Responsibilities include thefollowing:\n",
            "\n",
            "Work as a member of a cross-functional team to propose and implement high-impact data and analytic solutions that address business challenges across a variety of business units\n",
            "\n",
            "Apply Data Science and Modeling techniques to drive data driven decision making and solve complex business problems:\n",
            "\n",
            "Create breakthrough solutions, performing exploratory and targeted data analyses\n",
            "\n",
            "Build predictive models and machine-learning algorithms\n",
            "\n",
            "Analyze large amounts of diverse information to discover trends and patterns\n",
            "\n",
            "Undertake preprocessing of structured and unstructured data\n",
            "\n",
            "Monitor and sustain model effectiveness\n",
            "\n",
            "Combine models through ensemble modeling\n",
            "\n",
            "Present complex information using data visualization techniques\n",
            "\n",
            "Plan and execute projects, including direction and oversight of technical work of associate Data Scientists\n",
            "\n",
            "Work with diverse technical teams and provide data and analytic oversight to ensure project deliverables fulfill business needs and timing\n",
            "\n",
            "Identify long-term technical innovations and collaborate with the Analytics Research COE\n",
            "\n",
            "Minimum seven years of experience developing, deploying and monitoring performance of large analytic data sets and machine learning based models\n",
            "\n",
            "Minimum seven years of experience utilizing several of the following data and analytics toolsets:\n",
            "\n",
            "Languages: Python, R, Spark Scala, SAS\n",
            "\n",
            "Big Data Tools and Databases: Hadoop, Teradata, Spark, Kafka, Advanced SQL and NoSQL including Postgres and Cassandra\n",
            "\n",
            "Data Visualization: Tableau, SAS, JMP or similar\n",
            "\n",
            "Ability to prioritize and manage multiple tasks and projects at once without sacrificing quality\n",
            "\n",
            "Strong listening and communications skills\n",
            "\n",
            "Highly collaborative work style\n",
            "\n",
            "Ability to evaluate the big picture and solve business problems rather than focusing solely on metrics\n",
            "\n",
            "Education and Experience:\n",
            "\n",
            "PhD. or Master’s Degree in Mathematics, Statistics, Computer Science, Operations Research, Engineering, Economics or other quantitative field\n",
            "\n",
            "Preferred academic or work experience in a data-intensive field/industry such as biotechnology, computational chemistry, cognitive or neurosciences, behavioral economics, econometrics, engineering, physics, quantitative finance, high frequency trading or intelligence analytics\n",
            "\n",
            " GM is eagerly seeking new talent with fresh perspectives to inspire our innovative products and services. Join us on a journey to experie...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m31KjH3yfLS",
        "outputId": "a248a775-425d-4dce-e479-f5808218a7ce"
      },
      "source": [
        "# fifth sample\n",
        "\n",
        "output_article(df_misclassified.loc[list_samples[4]])"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual Category: Business/Consulting\n",
            "Predicted Category: Computer/Tech\n",
            "-------------------------------------------\n",
            "Text: \n",
            "Learn and work on meaningful initiatives with some of the best and brightest in the market research industry. The NPD Group provides the world’s most successful brands with leading market research, combining consumer and retail point-of-sale data with analytic solutions to interpret today’s market trends while anticipating tomorrow’s. In addition, we offer a career filled with innovation and growth to the forward-thinking problem solvers who join our team. Position Overview You’re a passionate, dynamic, and highly motivated individual who’s looking for an opportunity to have an impact on some of the most well-known companies in the world.  This integral member of the Research Sciences team will report directly to the Research Manager. If you enjoy working with clients to influence their business solutions, this job is for you. NPD’s Research Science Group works to ensure that NPD’s market information is of the highest quality; in particular, that it is reliable, accurate, and complete.  We design and monitor the systems that ensure quality outcomes through use of approaches such as: Missing data imputation Multi-level modeling Selection bias modeling Small area estimation Automatic categorization of purchase records Forecasting of future trends The demographic balance of questionnaire responses via sampling Post hoc adjustment (i.e., raking) This position exists within the Methodology and Protocols team, a core function in Research Science that is responsible for developing and promoting best practices across the organization and industry. Overall Responsibilities: Use SAS, SPSS, SQL, R, and/or Excel to: Design methodological enhancements to NPD processes Carry out tests of alternative implementations of these enhancements Conduct basic research that draws on existing NPD data to study different aspects of consumer reporting performance and POS data coverage Apply multivariate and machine learning techniques to the above problems Promote consistency in implementation of designed enhancements across different businesses Maintain relationships with Research Science client teams to understand what is working well with NPD methodology and what could be improved Communicate results and procedures to internal clients Qualifications: Advanced degree in statistics, preferably a PhD Two-plus years’ experience in: Statistical programming in SAS, SPSS and/or R Advanced statistical techniques (including those mentioned above) Knowledge of SQL queries preferred (either SAS Proc SQL or another SQL implementation)  Excellent project management, time management,  and problem solving skills Ability to communicate ideas and analysis results effectively both verbally and in writing to both technical and non-technical audiences Ability to work well on a team as well as independently Proficient in MS Office (MS Word, Excel and PowerPoint) Communication The ideal candidate must be able to conduct engaging and impactful presentations that deliver value to the client while telling a compelling story in a concise and polished manner to a diverse audience. Most importantly, the candidate must demonstrate the ability to listen to the customer and appropriately match the customer's needs with NPD’s products and services, or be willing to direct the customer to the best solution. Relationships The ideal candidate must be comfortable and effective when talking with a broad range of decision influencers and decision makers within an organization. The candidate will be able to effectively understand and build relationships throughout the prospective customer's organization. Discipline The ideal candidate will be competent in managing their time and activities and must embrace our proven opportunity and customer management processes and systems. Candidates must possess a \"can-do\" perspective in their professional attitude. They will be detail oriented and demonstrate a strong work ethic. They will be sticklers for accuracy in their own work as well as their colleagues. They will be ready to back up their assertions with facts. The NPD Group, Inc. is an Affirmative Action/Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status or any other characteristic protected by law.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu2jjlgH3ear"
      },
      "source": [
        "**Lets test our model on real life job postings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAWHqkMm3K8o",
        "outputId": "82e06357-3da1-487e-d429-de16c44db74d"
      },
      "source": [
        "# Downloading stopwords list\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL_W4Uvj3RJC"
      },
      "source": [
        "# Loading the stop words in english\n",
        "\n",
        "stop_words = list(stopwords.words('english'))"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1DMEfUb5oIx",
        "outputId": "967ba307-f148-424b-a414-3fa0ee65c989"
      },
      "source": [
        "# download wordnet\n",
        ")\n",
        "\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdiLA8vm7X_9",
        "outputId": "06ad18e6-ac4c-4df8-aed3-89ad0b68c3ba"
      },
      "source": [
        "# Copy our setup from feature selection (part 2)\n",
        "# Parameter election\n",
        "ngram_range = (1,2)\n",
        "min_df = 10\n",
        "max_df = 1.\n",
        "max_features = 300\n",
        "\n",
        "# define and fit TF-IDF vectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(encoding='utf-8',\n",
        "                        ngram_range=ngram_range,\n",
        "                        stop_words=None,\n",
        "                        lowercase=False,\n",
        "                        max_df=max_df,\n",
        "                        min_df=min_df,\n",
        "                        max_features=max_features,\n",
        "                        norm='l2',\n",
        "                        sublinear_tf=True)\n",
        "features_train = tfidf.fit_transform(X_train).toarray()\n",
        "labels_train = y_train\n",
        "print(\"Train features\", features_train.shape)\n",
        "\n",
        "features_test = tfidf.transform(X_test).toarray()\n",
        "labels_test = y_test\n",
        "print(\"Test features\", features_test.shape)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train features (1500, 300)\n",
            "Test features (500, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q7zj0IK2di-"
      },
      "source": [
        "punctuation_signs = list(\"?:!.,;\")\n",
        "stop_words = list(stopwords.words('english'))\n",
        "\n",
        "def create_features_from_text(text):\n",
        "    \n",
        "    # Dataframe creation\n",
        "    lemmatized_text_list = []\n",
        "    df = pd.DataFrame(columns=['job_description'])\n",
        "    df.loc[0] = text\n",
        "    df['Content_Parsed_1'] = df['job_description'].str.replace(\"\\r\", \" \")\n",
        "    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"\\n\", \" \")\n",
        "    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"    \", \" \")\n",
        "    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace('\"', '')\n",
        "    df['Content_Parsed_2'] = df['Content_Parsed_1'].str.lower()\n",
        "    df['Content_Parsed_3'] = df['Content_Parsed_2']\n",
        "    for punct_sign in punctuation_signs:\n",
        "        df['Content_Parsed_3'] = df['Content_Parsed_3'].str.replace(punct_sign, '')\n",
        "    df['Content_Parsed_4'] = df['Content_Parsed_3'].str.replace(\"'s\", \"\")\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_list = []\n",
        "    text = df.loc[0]['Content_Parsed_4']\n",
        "    text_words = text.split(\" \")\n",
        "    for word in text_words:\n",
        "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
        "    lemmatized_text = \" \".join(lemmatized_list)    \n",
        "    lemmatized_text_list.append(lemmatized_text)\n",
        "    df['Content_Parsed_5'] = lemmatized_text_list\n",
        "    df['Content_Parsed_6'] = df['Content_Parsed_5']\n",
        "    for stop_word in stop_words:\n",
        "        regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
        "        df['Content_Parsed_6'] = df['Content_Parsed_6'].str.replace(regex_stopword, '')\n",
        "    df = df['Content_Parsed_6']\n",
        "    #df = df.rename(columns={'Content_Parsed_6': 'Content_Parsed'})\n",
        "    \n",
        "    # TF-IDF\n",
        "    features = tfidf.transform(df).toarray()\n",
        "    \n",
        "    return features"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dj5Ga732xkg"
      },
      "source": [
        "def get_category_name(category_id):\n",
        "    for category, id_ in category_codes.items():    \n",
        "        if id_ == category_id:\n",
        "            return category"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgfHgYjo06u7"
      },
      "source": [
        "# let's try to predict a job posting category from a random job description\n",
        "\n",
        "def predict_from_text(text):\n",
        "    \n",
        "    # Predict using the input model\n",
        "    prediction_rfc = rfc_model.predict(create_features_from_text(text))[0]\n",
        "    prediction_rfc_proba = rfc_model.predict_proba(create_features_from_text(text))[0]\n",
        "    \n",
        "    # Return result\n",
        "    category_rfc = get_category_name(prediction_rfc)\n",
        "    \n",
        "    print(\"The predicted category using the RFC model is %s.\" %(category_rfc) )\n",
        "    print(\"The conditional probability is: %a\" %(prediction_rfc_proba.max()*100))\n"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0h8CKBp1WQu",
        "outputId": "9b64430b-7b38-4129-edef-c19287a00e12"
      },
      "source": [
        "text=\"\"\"\n",
        "\n",
        "Position: Director, Demand Conversion Data Science\n",
        "\n",
        "Hiring Leader: David Ralston, Senior Director Engagement Analytics\n",
        "\n",
        "Business Unit: Digital Media\n",
        "\n",
        "Location: Bay Area, CA preferred\n",
        "\n",
        "Our company\n",
        "\n",
        "Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver extraordinary digital experiences. We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.\n",
        "\n",
        "We’re on a mission to hire the very best and are committed to creating extraordinary employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!\n",
        "\n",
        "The challenge\n",
        "\n",
        "Use your expertise in marketing sciences to drive the next stage of growth for Adobe! You will bridge TAM and prospect audiences to identify and nurture consumers on their journey towards becoming long-tenured customers. Understanding of traffic sources, landing pages, and customer touch-points for each customer to enable optimization as we move from prospect to visitor to customer.\n",
        "\n",
        "This leader will work closely with paid media, content, campaign, and growth teams to deliver an outstanding experience for new and existing customers. A successful candidate will own the conversion funnel, including critical metrics, targets, and ongoing optimization. Also, the Director will develop a test framework, craft the testing roadmap, developing the personalization strategy, and executing the plan across every stage of our acquisition funnel.\n",
        "\n",
        "The ideal candidate will have hands-on experience with data science applied to digital marketing of subscription products/services and a passion for developing deep customer understanding that will advise optimization and personalization strategies. People, technology, and data science leadership combined with a strong focus on working with a diverse set to teams to deliver business results are important elements of this leadership role.\n",
        "\n",
        "What you’ll do\n",
        "Lead development of the demand conversion funnel, including all aspects of acquisition, nurture, conversion and advocacy stages of the customer journey. Deep understanding of TAM and how to reach prospective customers. Quantify health of traffic, trials and conversion to optimize, set strategy and inform investment\n",
        "Work with the GTM, Marketing and Campaign teams to strategize on the overall demand plan and build audiences for each event that ultimately translate to revenue.\n",
        "Develop a robust, performance-based test & learn plan, with a prioritized focus on the biggest opportunities\n",
        "Deliver innovative solutions to attribution and intent classification with the explicit goal of unlocking hidden opportunities for optimization.\n",
        "Deliver ongoing insights into performance and opportunities (unlocks) to exec audience including partnering with GTM and Marketing leaders on pricing, promo, trial, up/down/cross sell strategies\n",
        "Build critical metrics including free trial conversion rate, net new attach rates, up/cross/down-sell. You will have heavy influence over setting the target for these rates in the annual budget, and significant responsibility for ensuring that the company meets these targets.\n",
        "What you need to succeed\n",
        "10+ years of digital marketing & acquisition experience with a focus on performance marketing and demand conversion.\n",
        "Experience building and leading a large team, with an ongoing focus on mentorship and career development of highly technical team. Ideally has led teams of 10-15+.\n",
        "Advanced degree in related field with proven hands-on experience using diverse data to deliver conversion optimization\n",
        "Highly analytical attitude with a deep understanding of acquisition funnel, economics and profitability levers\n",
        "Strong leadership skills, with the ability to work optimally with multiple partners.\n",
        "Subscription business model and/or digital product industry experience (agency or corporate) a plus\n",
        "\n",
        "At Adobe, you will be immersed in an exceptional work environment that is recognized around the world. You will also be surrounded by colleagues who are committed to helping each other grow through our unique Check-In approach where ongoing feedback flows freely. If you’re looking to make an impact, Adobe's the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog and explore the meaningful benefits we offer.\n",
        "\n",
        "Adobe is an equal opportunity employer. We hire hard working individuals, regardless of gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, or veteran status. We know that when our employees feel appreciated and included, they can be more creative, innovative and successful. This is what it means to be Adobe For All. Learn more about our vision here.\n",
        "\n",
        "We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "predict_from_text(text)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted category using the RFC model is Computer/Tech.\n",
            "The conditional probability is: 55.07815950655625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIiOvMdc8c6h",
        "outputId": "d0ce9730-88a8-4f22-f33d-4d2946a1cfbb"
      },
      "source": [
        "text=\"\"\"\n",
        "Interested in being a part being a part of a multi-billion dollar international organization? Our Client is looking for a Data Scientist to work within their rapidly growing IoT Lab in the heart of Silicon Valley. This opportunity will be working on projects anywhere from home automation and autonomous vehicles to the connectivity between devices.\n",
        "\n",
        "You will be working with different projects with a talented team of backend, mobile, and front end engineers. They are looking for someone who will work directly with executive teams of leading companies, getting great visibility within the company.\n",
        "\n",
        "Required Skills & Experience\n",
        "B.S./M.S. in Computer Science, Engineering or related\n",
        "2-3+ years of Data Science / ML experience\n",
        "Proficiency in Python ML Libraries / Packages\n",
        "Experienced with cloud technology: AWS, EC2, & S3\n",
        "Strong Design, Analytical Skills, and excellent communication skills\n",
        "Experience developing large-scale distributed systems\n",
        "\n",
        "\n",
        "Desired Skills & Experience\n",
        "Experience building a data-processing pipeline is big plus\n",
        "\n",
        "Benefits & Perks\n",
        "\n",
        "Competitive Salary DOE, Early Stage Equity, Benefits\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "predict_from_text(text)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted category using the RFC model is Business/Consulting.\n",
            "The conditional probability is: 49.82238349885409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzhgfwZA8vqA",
        "outputId": "1d879880-4318-4617-9531-e31324159155"
      },
      "source": [
        "text=\"\"\"\n",
        "Overview\n",
        "As USAC continues to support universal service impacting health care providers, educators, and\n",
        "consumers, it is critical now more than ever that we hire people equally passionate and\n",
        "committed to helping fulfill our mission. We are currently seeking an experienced, dynamic and\n",
        "collaborative professional to serve as Data Analyst within on our Data Strategy team. \n",
        "Reporting to the Senior Manager of Data Strategy and Insight you will:\n",
        " performs data reporting and analytics, including requirements gathering for reports,\n",
        "aggregating and presenting information from various programmatic data sources for\n",
        "monthly and quarterly reporting purposes.\n",
        "This is an outstanding career opportunity for an individual interested in a genuine professional\n",
        "challenge in support of a public-spirited mission.\n",
        "Responsibilities\n",
        "Working in a creative and fast-paced environment, the Data Analyst&#39;s responsibilities will\n",
        "include the following:\n",
        " Analyze large sets of program data to identify opportunities to improve the efficiency,\n",
        "integrity, and stakeholder experience of Universal Service program participants.\n",
        " Perform research and analysis using programmatic data, to relay programmatic impacts,\n",
        "trends, patterns, statistics, etc. across the company.\n",
        " Recommend program process improvements based on data while maintaining reporting\n",
        "standards while ensuring consistency and quality of deliverables.\n",
        " Create and maintain queries using SQL or other programming languages (with a\n",
        "preference for Open Source programming languages such as R and Python) as necessary\n",
        "for consistency and efficiency of data retrieval from various systems.\n",
        " Research methods and tools to create efficiency for reporting, GIS mapping, and other\n",
        "analytical and computational processes.\n",
        " Maintain, develop, and implement policies and procedures that ensure the accuracy and\n",
        "integrity of USAC program data and reporting.\n",
        " Participate in the evaluation of new technologies to ensure the technology architecture\n",
        "and data analysis and visualization tools are in line with company’s evolving business\n",
        "intelligence needs.\n",
        " Support managers, directors, and members of the leadership team in various projects,\n",
        "as needed.\n",
        " Other specific duties as assigned.\n",
        " \n",
        "About You\n",
        " \n",
        "The successful candidate will excel at operating in a diverse and fluid environment, and will be\n",
        "crucial for the success of the Date Strategy team.\n",
        "\n",
        " You possess Bachelor’s degree from an accredited institution in a related field.\n",
        " Three (3) to Four (4) years of professionally related experience.\n",
        " Experience in the data science field performing descriptive, predictive, and prescriptive\n",
        "analysis and developing data products and tools that provide actionable insights and\n",
        "strategic guidance to managers and people in leadership positions.\n",
        " Ability to work independently, but also collaborate and work across other departments\n",
        "as needed.\n",
        " Proven experience working with data warehoused in databases using SQL and\n",
        "programming languages for data science such as R or Python (or a demonstrated\n",
        "capacity to learn them).\n",
        " Experience presenting complex analysis and results in plain English for a non-technical\n",
        "audience using data visualizations (i.e. charts, tables, and graphs) on various software\n",
        "platforms.\n",
        " Excellent written and verbal communication skills, are naturally curious and inquisitive,\n",
        "and are interested in continuously improving our work.\n",
        " Excellent analytical skills with the ability to collect, organize, analyze, and disseminate\n",
        "significant amounts of information with attention to detail and accuracy.\n",
        " Proficient with Microsoft Office Suite.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "predict_from_text(text)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted category using the RFC model is Computer/Tech.\n",
            "The conditional probability is: 46.186765176701755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rDIWfD-8xmi",
        "outputId": "b9ffb723-d31a-4294-b899-2a081215ff1d"
      },
      "source": [
        "# fun fact: I tried testing with a job description for food manager in hospitality and this is what I got :)\n",
        "\n",
        "text=\"\"\"\n",
        "\n",
        "The Ingleside Hotel and Springs Water Park in Pewaukee is adding an experienced Food and Beverage Manager to our management team. If you have experience in banquet, restaurant or bar management and have strong leadership, organizational, communication, and guest service skills, this would be a perfect fit. You will help manage operations for our banquets, restaurant and water park snack bar. Position is primarily PM shift, including weekends and holidays. Must have (or obtain) a Waukesha bartending license.\n",
        "We have a reputation for providing extraordinary service, impeccable facilities and superb cuisine. As the Food and Beverage Manager, you will be responsible for ensuring we are achieving that vision. We offer you a family atmosphere and supportive management. Full benefit package + fun perks! EOE/M/F/D/V/SO\n",
        "\"\"\"\n",
        "\n",
        "predict_from_text(text)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted category using the RFC model is Business/Consulting.\n",
            "The conditional probability is: 67.36168497190039\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}